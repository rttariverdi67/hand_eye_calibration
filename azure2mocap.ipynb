{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os, copy, cv2\n",
    "sys.path.append('/home/rahim/Desktop/projects/mrob/build/mrobpy/')\n",
    "import mrob\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx=918.7847900390624\n",
    "fy=918.74755859375\n",
    "cx=959.554443359375\n",
    "cy=553.0713500976563\n",
    "\n",
    "camera_matrix_azure = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "dist_coeff_azure = np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/rahim/patata/datasets/navigine/mocab/apriltag/Azure/mocap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/color_pr/000027006844.png', '/depth_pr/000027006866.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_associations(root_dir, idx):\n",
    "    with open(root_dir+'/associations.txt') as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "\n",
    "    associations = []\n",
    "\n",
    "    for i in lines:\n",
    "        associations.append(i.split(\" \")[1::2])\n",
    "\n",
    "    return associations[idx-1]\n",
    "read_associations(root_dir,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quat_to_SE3(quat_pose):\n",
    "    \n",
    "    rot_4x1 = quat_pose[-4:]\n",
    "    tra_3x1 = quat_pose[1:4]\n",
    "\n",
    "    rot = mrob.geometry.quat_to_so3(rot_4x1)\n",
    "    pose = mrob.geometry.SE3(mrob.geometry.SO3(rot),tra_3x1)\n",
    "\n",
    "    return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ax(pose, size = 0.1):\n",
    "    axis = o3d.geometry.TriangleMesh.create_coordinate_frame(size=size)\n",
    "    return axis.transform(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mocap_poses = pd.read_csv(root_dir+'/Azure_mocap_apriltag_color_gt.csv', header=None, sep=\"\\s+\")\n",
    "mocap_quat = np.array([each for _,each in mocap_poses.iterrows()])\n",
    "\n",
    "# orb_poses = pd.read_csv(root_dir+'/CameraTrajectory.txt', header=None, sep=\"\\s+\")\n",
    "# orb_quat = np.array([each for _,each in orb_poses.iterrows()])\n",
    "\n",
    "mocap = np.zeros((mocap_quat.shape[0],4,4))\n",
    "# orb = np.zeros((mocap_quat.shape[0],4,4))\n",
    "for i in range(len(mocap_quat)):\n",
    "    mocap[i,:,:] = (quat_to_SE3(mocap_quat[i,:])).T()\n",
    "    # orb[i,:,:] = (quat_to_SE3(orb_quat[i,:])).T()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(root_dir, idx):\n",
    "\n",
    "    pairs = read_associations(root_dir,idx)\n",
    "    color_dir = root_dir + pairs[0]\n",
    "    depth_dir = root_dir + pairs[1]\n",
    "    \n",
    "    color = o3d.t.io.read_image(color_dir)\n",
    "    depth = o3d.t.io.read_image(depth_dir)\n",
    "    return color, depth\n",
    "c, d = get_data(root_dir, 561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloud with 152611 points."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pcd_pose(root_dir, camera_matrix, idx):\n",
    "\n",
    "    color, depth = get_data(root_dir, idx)\n",
    "\n",
    "    cam = o3d.camera.PinholeCameraIntrinsic()\n",
    "    cam.intrinsic_matrix = camera_matrix\n",
    "\n",
    "    rgbd = o3d.t.geometry.RGBDImage(color, depth)\n",
    "                                   \n",
    "    pcd = o3d.t.geometry.PointCloud.create_from_rgbd_image(rgbd, camera_matrix, depth_scale=1000.0, depth_max=3.0)\n",
    "    pcd = pcd.to_legacy()\n",
    "\n",
    "    return pcd\n",
    "\n",
    "pcd = get_pcd_pose(root_dir, camera_matrix_azure, 541)\n",
    "pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(root_dir, camera_matrix, dist_coeff, idx):\n",
    "\n",
    "    aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_5X5_100)\n",
    "    # Note: Pattern generated using the following link\n",
    "    # https://calib.io/pages/camera-calibration-pattern-generator\n",
    "    board = cv2.aruco.CharucoBoard_create(14, 9, 0.03975, 0.02975, aruco_dict)\n",
    "    # (columns:squaresX, rows:squaresY, Checker Width: squareLength, markerLength, markers type)\n",
    "\n",
    "    pairs = read_associations(root_dir,idx)\n",
    "    color_dir = root_dir + pairs[0]\n",
    "\n",
    "    all_corners, all_ids, T_arucos = [], [], []\n",
    "    frame = cv2.imread(color_dir)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray, aruco_dict)\n",
    "    if len(corners) > 0:\n",
    "        ret, c_corners, c_ids = cv2.aruco.interpolateCornersCharuco(corners, ids, gray, board)\n",
    "        if ret > 0:\n",
    "            all_corners.append(c_corners)\n",
    "            all_ids.append(c_ids)\n",
    "    imsize = gray.shape\n",
    "\n",
    "    all_corners = [x for x in all_corners if len(x) >= 4]\n",
    "    all_ids = [x for x in all_ids if len(x) >= 4]\n",
    "    ret, _, _, rvec, tvec = cv2.aruco.calibrateCameraCharuco(\n",
    "        all_corners, all_ids, board, imsize, None, None)\n",
    "\n",
    "    ret, p_rvec, p_tvec = cv2.aruco.estimatePoseCharucoBoard(charucoCorners=c_corners,\n",
    "                                                                charucoIds=c_ids,\n",
    "                                                                board=board,\n",
    "                                                                cameraMatrix=camera_matrix,\n",
    "                                                                distCoeffs=dist_coeff, \n",
    "                                                                rvec=0*rvec[0], \n",
    "                                                                tvec=0*tvec[0],\n",
    "                                                                )\n",
    "    # if ret>0:                                                           \n",
    "    #     ax = cv2.drawFrameAxes(frame,\n",
    "    #                             camera_matrix,\n",
    "    #                             dist_coeff,\n",
    "    #                             p_rvec,\n",
    "    #                             p_tvec,\n",
    "    #                             0.1)\n",
    "    #     plt.figure(figsize=(22,18)) \n",
    "    #     plt.imshow(ax) \n",
    "    #     plt.savefig(f'/home/r/Desktop/new_project_dir/mrob/figs/{os.path.basename(pairs[0])}')                      \n",
    "    #     # plt.show()\n",
    "    #     plt.figure().clear()\n",
    "    #     plt.close()\n",
    "\n",
    "    T_aruco = mrob.geometry.SE3(mrob.geometry.SO3(p_rvec),p_tvec)\n",
    "    return T_aruco, pairs[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$^{m}T_{af}^{-1} \\cdot ^{m}T_f = ^{af}T_a \\cdot ^{c}T_a^{-1} \\cdot ^{c}T_f$$\n",
    "\n",
    "$$^{af}T_f = Y \\cdot ^{a}T_c \\cdot X$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:40<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "AT_C = []\n",
    "MT_F = []\n",
    "pcds = []\n",
    "\n",
    "\n",
    "for idx in tqdm(range(0, 1000, 10)):\n",
    "    pairs = read_associations(root_dir,idx)\n",
    "    try:\n",
    "        cT_a, name = main(root_dir, camera_matrix_azure, dist_coeff_azure, idx)\n",
    "        pcd = get_pcd_pose(root_dir, camera_matrix_azure, idx)\n",
    "        # we need aT_c in formula\n",
    "        AT_C.append(cT_a.inv())\n",
    "        MT_F.append(mocap[idx-1])\n",
    "        pcds.append(pcd)\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mT_af_q = [0.0, -0.774173, 1.020377, 2.115314, 0.004979, 0.846904, -0.531174, 0.024143]\n",
    "mT_af = quat_to_SE3(mT_af_q)\n",
    "AFT_M = mT_af.inv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MT_F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m AFT_F \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m mT_f \u001b[39min\u001b[39;00m MT_F:\n\u001b[1;32m      3\u001b[0m     AFT_F\u001b[39m.\u001b[39mappend(AFT_M\u001b[39m.\u001b[39mmul(mrob\u001b[39m.\u001b[39mgeometry\u001b[39m.\u001b[39mSE3(mT_f)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MT_F' is not defined"
     ]
    }
   ],
   "source": [
    "AFT_F = []\n",
    "for mT_f in MT_F:\n",
    "    AFT_F.append(AFT_M.mul(mrob.geometry.SE3(mT_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AFT_F_ax=[ax(AFT_F[i].T(), 0.05) for i in range(len(AFT_F))]\n",
    "AT_C_ax=[ax(AT_C[i].T(), 0.1) for i in range(len(AT_C))]\n",
    "# ax_list.append(ax(mT_af.T(), 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(AFT_F_ax+AT_C_ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in image below, up are poses from mocap and down are poses from ruco-marker. we used opeencv for that. as shown in abowe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Getting Started](./Azure_mocap_poses_before_calibration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$^{af}T_m \\cdot ^{m}T_f = ^{af}T_a \\cdot ^{a}T_c \\cdot ^{c}T_f$$\n",
    "\n",
    "$$^{af}T_f = Y \\cdot ^{a}T_c \\cdot X$$\n",
    "\n",
    "as defined in the factor:\n",
    "    $$T_{obs2} =  Y_{origin} \\cdot T_{obs1} \\cdot X_{target}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of graph:  Nodes = 2, Factors = 0, Eigen Factors = 0\n",
      "Printing NodePose3d: 0, state = \n",
      "-0\n",
      " 0\n",
      "-0\n",
      " 0\n",
      " 0\n",
      " 0,\n",
      " SE3 matrix: \n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "Printing NodePose3d: 1, state = \n",
      "-0\n",
      " 0\n",
      "-0\n",
      " 0\n",
      " 0\n",
      " 0,\n",
      " SE3 matrix: \n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 1##############################\n",
      "Y= \n",
      " [[-0.99971456 -0.02228952  0.00860053  0.28782298]\n",
      " [-0.00816474 -0.01956904 -0.99977517 -0.03647737]\n",
      " [ 0.02245281 -0.99956002  0.01938146  0.25678577]\n",
      " [ 0.          0.          0.          1.        ]] \n",
      "X=\n",
      " [[ 0.99974679 -0.0033099   0.02225774 -0.06345485]\n",
      " [-0.00326866 -0.99999287 -0.00188887 -0.03740818]\n",
      " [ 0.02226383  0.00181564 -0.99975048 -0.22397985]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      " lambda = 1e-05, error 262.781, and delta = -71.5976\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 2 lambda = 2e-05, error 262.781, and delta = -71.5926\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 3 lambda = 4e-05, error 262.781, and delta = -71.5826\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 4 lambda = 8e-05, error 262.781, and delta = -71.5626\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 5 lambda = 0.00016, error 262.781, and delta = -71.5227\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 6 lambda = 0.00032, error 262.781, and delta = -71.4428\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 7 lambda = 0.00064, error 262.781, and delta = -71.2834\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 8 lambda = 0.00128, error 262.781, and delta = -70.9657\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 9 lambda = 0.00256, error 262.781, and delta = -70.3348\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 10 lambda = 0.00512, error 262.781, and delta = -69.0904\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 11 lambda = 0.01024, error 262.781, and delta = -66.6694\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 12 lambda = 0.02048, error 262.781, and delta = -62.0816\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 13 lambda = 0.04096, error 262.781, and delta = -53.6294\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 14 lambda = 0.08192, error 262.781, and delta = -39.1541\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 15 lambda = 0.16384, error 262.781, and delta = -17.2161\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 16 lambda = 0.32768, error 262.781, and delta = 16.1543\n",
      "model fidelity = 0.130236 and m_k = 248.077\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 17 lambda = 0.65536, error 246.627, and delta = 70.799\n",
      "model fidelity = 0.426141 and m_k = 332.28\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 18 lambda = 0.65536, error 175.828, and delta = 143.196\n",
      "model fidelity = 0.878154 and m_k = 326.13\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 19 lambda = 0.16384, error 32.6316, and delta = 25.7388\n",
      "model fidelity = 0.965772 and m_k = 53.302\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 20 lambda = 0.04096, error 6.89279, and delta = 5.75316\n",
      "model fidelity = 1.10956 and m_k = 10.3702\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 21 lambda = 0.01024, error 1.13962, and delta = 1.08666\n",
      "model fidelity = 0.997518 and m_k = 2.17872\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 22 lambda = 0.00256, error 0.0529672, and delta = 0.0262076\n",
      "model fidelity = 0.998477 and m_k = 0.0524952\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 23 lambda = 0.00064, error 0.0267596, and delta = 8.89499e-06\n",
      "model fidelity = 0.967501 and m_k = 1.83876e-05\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: iteration 24 lambda = 0.00016, error 0.0267507, and delta = 1.09588e-08\n",
      "\n",
      "FGraphSolve::optimize_levenberg_marquardt: Converged Successfully\n"
     ]
    }
   ],
   "source": [
    "def solver(gt, orb):\n",
    "\n",
    "    gt = np.asarray([i.T() for i in gt])\n",
    "    orb = np.asarray([i.T() for i in orb])\n",
    "    Y_ini = mrob.geometry.SE3() #gt[0,:,:]).inv()\n",
    "    X_ini = mrob.geometry.SE3()\n",
    "\n",
    "    graph = mrob.FGraph()\n",
    "    W_0 = 1e0*np.identity(6)\n",
    "    W = np.identity(6)\n",
    "    iy = graph.add_node_pose_3d(Y_ini)\n",
    "    ix = graph.add_node_pose_3d(X_ini)\n",
    "    #graph.add_factor_1pose_3d(X_ini,ix,W_0)\n",
    "    #graph.add_factor_1pose_3d(Y_ini,iy,W_0)\n",
    "    graph.print(True)\n",
    "    results = graph.get_estimated_state()\n",
    "    # print('Initial conditions:\\n',results[0],'\\n',results[1])\n",
    "\n",
    "    # adding all poses or some of them. Residual is r = Ln ( T_o * T_obs * T_t * T_obs2^-1 )\n",
    "    # There is aproblem with the second observation... but for gradients\n",
    "    for i in range(len(gt)):\n",
    "        T_gt = mrob.geometry.SE3(gt[i,:,:])\n",
    "        T_orb = mrob.geometry.SE3(orb[i,:,:])\n",
    "        graph.add_factor_2poses_3d_2obs(obs = T_gt,\n",
    "                                obs2 = T_orb,\n",
    "                                nodeOriginId = iy,\n",
    "                                nodeTargetId = ix,\n",
    "                                obsInvCov = W)\n",
    "\n",
    "    graph.solve(mrob.LM, 100, solutionTolerance=1e-6)\n",
    "\n",
    "    results = graph.get_estimated_state()\n",
    "    \n",
    "    # np.save('results.npy', results)\n",
    "\n",
    "    # afY_a = results[0] \n",
    "    # fX_c = results[1]\n",
    "\n",
    "    # return afY_a, fX_c\n",
    "    return results\n",
    "\n",
    "\n",
    "results = solver(AT_C, AFT_F)\n",
    "print('#'*30)\n",
    "print('Y= \\n', results[0],'\\nX=\\n',results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99974679, -0.00326866,  0.02226383,  0.06830316],\n",
       "       [-0.0033099 , -0.99999287,  0.00181564, -0.03721128],\n",
       "       [ 0.02225774, -0.00188887, -0.99975048, -0.22258226],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# help(mrob.FGraph.add_factor_2poses_3d_2obs)\n",
    "\n",
    "CT_F = mrob.geometry.SE3(results[1])\n",
    "FT_C = CT_F.inv().T()\n",
    "FT_C\n",
    "# np.save('FT_C_azure', FT_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FT_C = np.load('./FT_C_azure.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds_glob = []\n",
    "azure_poses = []\n",
    "for pcd, mT_fi in zip(pcds, MT_F):\n",
    "    mT_fi = mrob.geometry.SE3(mT_fi)\n",
    "    mT_c = mT_fi * CT_F.inv()\n",
    "    pcds_glob.append(pcd.transform(mT_c.T()))\n",
    "    azure_poses.append(mT_c.T())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(pcds_glob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Getting Started](./calibration_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we found calibration. what we do:\n",
    "\n",
    "take pose from mocap($^{M}T_F$), and  multiply it to inverse of $X$, again $X$ here based on our chain, is $^{C}T_{F}$, frame to camera, and this multiplication will give you pose from Azure camera to mocap, IOW, global pose.\n",
    "\n",
    "$$^{M}T_C = ^{M}T_F \\cdot X^{-1} = ^{M}T_F \\cdot ^{C}T_F^{-1}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds_all = [get_pcd_pose(root_dir, camera_matrix_azure, idx) for idx in range(0, len(mocap), 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FT_C = np.load('./FT_C_azure.npy')\n",
    "# CT_F = mrob.geometry.SE3(FT_C).inv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds_map = []\n",
    "azure_pos = []\n",
    "for pcd, mT_fi in zip(pcds_all, mocap[::50]):\n",
    "    mT_fi = mrob.geometry.SE3(mT_fi)\n",
    "    mT_c = mT_fi * CT_F.inv()\n",
    "    pcds_map.append(copy.deepcopy(pcd).transform(mT_c.T()))\n",
    "    azure_pos.append(mT_c.T())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.997924  ,  0.03902632, -0.05123119, -0.75173797],\n",
       "       [-0.0173995 , -0.9292774 , -0.36897259,  1.29246891],\n",
       "       [-0.06200763, -0.36731521,  0.92802726,  0.97458113],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries(pcds_map[5:]+[ax(i) for i in azure_pos])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Getting Started](./azure_map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lab_cloud = o3d.geometry.PointCloud()\n",
    "# for pcd in pcds_map[5:]:\n",
    "#     points = np.concatenate((np.asarray(lab_cloud.points), np.asarray(pcd.points)), axis=0)\n",
    "#     colors = np.concatenate((np.asarray(lab_cloud.colors), np.asarray(pcd.colors)), axis=0)\n",
    "#     lab_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "#     lab_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# o3d.io.write_point_cloud('lab_cloud.pcd', lab_cloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
